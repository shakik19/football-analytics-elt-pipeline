############################    CREDENTIALS    ################################
GOOGLE_APPLICATION_CREDENTIALS="/usr/local/airflow/include/keys/gcp_key.json"
KAGGLE_USERNAME=""
KAGGLE_KEY=""

############################     GCP VARS     #################################
PROJECT_ID=""
BUCKET_NAME=""
STAGING_DATASET_NAME=""
CORE_DATASET_NAME=""
REGION="us-central1"    # Must be the same as defined in terraform

# Transfermarkt specific DAG configs
TM_DAG_MAX_ACTIVE_RUNS=1
TM_DAG_MAX_ACTIVE_TASKS=4

ENV_NAME="dev"


## Uncomment the AIRFLOW configs below in case you get ZOMBIE JOB ERROR
############################   AIRFLOW CONFIG  ###############################
# WARNING: DON'T CHANGE ANY CONFIGS BELOW UNLESS YOU REALLY NEED TO 
# CHANGES IN SOME CONFIG MAY CAUSE ZOMBIE JOB ERROR
# THE PROJECT IS TESTED USING BELOW CONFIG

#! [scheduler]
# Task instances listen for external kill signal (when you clear tasks from the 
# CLI or the UI), this defines the frequency at which they should listen (in seconds).
# AIRFLOW__SCHEDULER__JOB_HEARTBEAT_SEC=300

# The frequency (in seconds) at which the LocalTaskJob should send heartbeat 
# signals to the scheduler to notify itâ€™s still alive. If this value is
# set to 0, the heartbeat interval will default to the value of scheduler_zombie_task_threshold.
# AIRFLOW__SCHEDULER__LOCAL_TASK_JOB_HEARTBEAT_SEC=5

# Local task jobs periodically heartbeat to the DB. If the job has not heartbeat
# in this many seconds, the scheduler will mark the associated task instance as
# failed and will re-schedule the task
# AIRFLOW__SCHEDULER__SCHEDULER_ZOMBIE_TASK_THRESHOLD=600

# How often (in seconds) should the scheduler check for zombie tasks
# AIRFLOW__SCHEDULER__ZOMBIE_DETECTION_INTERVAL=1800

#! [core]
# When a task is killed forcefully, this is the amount of time in seconds that
# it has to cleanup after it is sent a SIGTERM, before it is SIGKILLED
# AIRFLOW__CORE__KILLED_TASK_CLEANUP_TIME=1800
# AIRFLOW__CORE__DEFAULT_TASK_EXECUTION_TIMEOUT=600
# AIRFLOW__CORE__DEFAULT_TASK_RETRIES=2